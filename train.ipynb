{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\karso\\anaconda3\\envs\\bootcampDev\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_4-H CLUBS &amp; AFFILIATED 4-H ORGANIZATIONS</th>\n",
       "      <th>NAME_AACE INTERNATIONAL</th>\n",
       "      <th>NAME_ACADEMY OF GENERAL DENTISTRY</th>\n",
       "      <th>NAME_ACADEMY OF MANAGED CARE PHARMACY</th>\n",
       "      <th>NAME_ACE MENTOR PROGRAM OF AMERICA INC</th>\n",
       "      <th>NAME_ACTIVE 20-30 UNITED STATES AND CANADA</th>\n",
       "      <th>NAME_ACTS MINISTRY</th>\n",
       "      <th>NAME_ACTS MISSIONS</th>\n",
       "      <th>NAME_AFRICAN-AMERICAN POSTAL LEAGUE UNITED FOR SUCCESS A-PLUS</th>\n",
       "      <th>NAME_AGENTS ASSOCIATION</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_1</th>\n",
       "      <th>INCOME_AMT_2</th>\n",
       "      <th>INCOME_AMT_3</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 825 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME_4-H CLUBS & AFFILIATED 4-H ORGANIZATIONS  NAME_AACE INTERNATIONAL  \\\n",
       "0                                              0                        0   \n",
       "1                                              0                        0   \n",
       "2                                              0                        0   \n",
       "3                                              0                        0   \n",
       "4                                              0                        0   \n",
       "\n",
       "   NAME_ACADEMY OF GENERAL DENTISTRY  NAME_ACADEMY OF MANAGED CARE PHARMACY  \\\n",
       "0                                  0                                      0   \n",
       "1                                  0                                      0   \n",
       "2                                  0                                      0   \n",
       "3                                  0                                      0   \n",
       "4                                  0                                      0   \n",
       "\n",
       "   NAME_ACE MENTOR PROGRAM OF AMERICA INC  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "\n",
       "   NAME_ACTIVE 20-30 UNITED STATES AND CANADA  NAME_ACTS MINISTRY  \\\n",
       "0                                           0                   0   \n",
       "1                                           0                   0   \n",
       "2                                           0                   0   \n",
       "3                                           0                   0   \n",
       "4                                           0                   0   \n",
       "\n",
       "   NAME_ACTS MISSIONS  \\\n",
       "0                   0   \n",
       "1                   0   \n",
       "2                   0   \n",
       "3                   0   \n",
       "4                   0   \n",
       "\n",
       "   NAME_AFRICAN-AMERICAN POSTAL LEAGUE UNITED FOR SUCCESS A-PLUS  \\\n",
       "0                                                  0               \n",
       "1                                                  0               \n",
       "2                                                  0               \n",
       "3                                                  0               \n",
       "4                                                  0               \n",
       "\n",
       "   NAME_AGENTS ASSOCIATION  ...  ORGANIZATION_Trust  INCOME_AMT_1  \\\n",
       "0                        0  ...                   0             0   \n",
       "1                        0  ...                   0             1   \n",
       "2                        0  ...                   0             0   \n",
       "3                        0  ...                   1             1   \n",
       "4                        0  ...                   1             0   \n",
       "\n",
       "   INCOME_AMT_2  INCOME_AMT_3  INCOME_AMT_0  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0             0             0             1                         1   \n",
       "1             0             0             0                         1   \n",
       "2             0             0             1                         1   \n",
       "3             0             0             0                         1   \n",
       "4             1             0             0                         1   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  STATUS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0                         0       1     5000              1  \n",
       "1                         0       1   108590              1  \n",
       "2                         0       1     5000              0  \n",
       "3                         0       1     6692              1  \n",
       "4                         0       1   142590              1  \n",
       "\n",
       "[5 rows x 825 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start be creating a copy for the preprocessing to occur\n",
    "pre = df.copy()\n",
    "# Drop off the id column\n",
    "pre = pre.drop(['EIN'],axis=1)\n",
    "\n",
    "# Define a function to bin categorical variables\n",
    "# First, we want to take in the Series for binning and the cutoff value\n",
    "def cat_binner(Series, cutoff_val):\n",
    "    # Save the value_counts for the Series in a variable 'counts'\n",
    "    counts = Series.value_counts()\n",
    "    # Save a list of the unique values that do not have more entries than the cutoff_val\n",
    "    counts_to_replace = list(counts[counts < cutoff_val].index)\n",
    "    # Run a for loop through those values and bin them as \"Other\"\n",
    "    for count in counts_to_replace:\n",
    "        Series = Series.replace(count,\"Other\")\n",
    "    # Return the Series\n",
    "    return Series\n",
    "\n",
    "# Use our cat_binner() function to bin categorical data\n",
    "# The goal is to capture as much of the variance of the model as possible without \n",
    "# overfitting the model as to maximize testing accuracy.\n",
    "pre[\"NAME\"] = cat_binner(pre[\"NAME\"], 2)\n",
    "pre[\"APPLICATION_TYPE\"] = cat_binner(pre[\"APPLICATION_TYPE\"], 1000)\n",
    "pre[\"CLASSIFICATION\"] = cat_binner(pre[\"CLASSIFICATION\"], 700)\n",
    "pre[\"AFFILIATION\"] = cat_binner(pre[\"AFFILIATION\"], 700)\n",
    "pre[\"USE_CASE\"] = cat_binner(pre[\"USE_CASE\"], 700)\n",
    "\n",
    "# Next, we want to reduce variation by binning significant INCOME_AMT data in 4 bins rather than 10\n",
    "# Define the value ranges to evaluate the bins\n",
    "# 0 ~ 0\n",
    "# low - 1\n",
    "loBin = ['1-9999','10000-24999','25000-99999']\n",
    "# mid -2 \n",
    "miBin = ['100000-499999','1M-5M']\n",
    "# high - 3\n",
    "hiBin = ['5M-10M','10M-50M','50M+']\n",
    "\n",
    "# Define a function to bin the INCOME_AMT variance\n",
    "# The function requires the list of values in each bin, the data, and the number being assigned\n",
    "def quant_binner(bin, df, assign):\n",
    "    # Run a for loop through the value range\n",
    "    for y in bin:\n",
    "        # Wherever the INCOME_AMT matches a value in the range, we assign the assigned value\n",
    "        df.loc[df[\"INCOME_AMT\"] == y, \"INCOME_AMT\" ] = assign\n",
    "    # Return the data\n",
    "    return df\n",
    "# Push this function through our data to bin INCOME_AMT\n",
    "pre = quant_binner(loBin, pre, 1)    \n",
    "pre = quant_binner(miBin, pre, 2)\n",
    "pre = quant_binner(hiBin, pre, 3)   \n",
    "\n",
    "# List comprehension for all the column names\n",
    "pre_cols = [ str(x) for x in pre.columns ]\n",
    "# List comprehension for the object columns\n",
    "obj_cols = [x for x in pre_cols if pre[x].dtype == 'object']\n",
    "# List comprehension for the integer columns\n",
    "int_cols = [x for x in pre_cols if pre[x].dtype == 'int64']\n",
    "# Encode the object columns with dummies\n",
    "obj_dummies = pd.get_dummies(pre[obj_cols], dtype=int)\n",
    "# Save DataFrame object of all integer columns\n",
    "int_dummies = pre[int_cols]\n",
    "# Concat dummies with integer columns\n",
    "pro = pd.concat([obj_dummies,int_dummies], axis=1)\n",
    "# Print for clarification\n",
    "pro.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train, Evaluate and Optimize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split \n",
    "# Training data is everything except the predicted value\n",
    "X = pro.drop(\"IS_SUCCESSFUL\",axis=1)\n",
    "# Save predicted value into y variable\n",
    "y = pro[\"IS_SUCCESSFUL\"]\n",
    "# Use train_test_split to nicely split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Scale Training Data\n",
    "# Define the scalar object\n",
    "scaler = StandardScaler()\n",
    "# Fit scalar with training data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "# Scale training set\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "# Scale testing set\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.4799 - accuracy: 0.7759\n",
      "Epoch 2/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4307 - accuracy: 0.8000\n",
      "Epoch 3/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4243 - accuracy: 0.8049\n",
      "Epoch 4/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4207 - accuracy: 0.8055\n",
      "Epoch 5/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4185 - accuracy: 0.8059\n",
      "Epoch 6/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4178 - accuracy: 0.8077\n",
      "Epoch 7/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4165 - accuracy: 0.8079\n",
      "Epoch 8/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4157 - accuracy: 0.8077\n",
      "Epoch 9/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4156 - accuracy: 0.8084\n",
      "Epoch 10/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4143 - accuracy: 0.8085\n",
      "Epoch 11/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4134 - accuracy: 0.8090\n",
      "Epoch 12/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4135 - accuracy: 0.8090\n",
      "Epoch 13/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4128 - accuracy: 0.8087\n",
      "Epoch 14/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4122 - accuracy: 0.8092\n",
      "Epoch 15/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4117 - accuracy: 0.8099\n",
      "Epoch 16/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4112 - accuracy: 0.8106\n",
      "Epoch 17/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4106 - accuracy: 0.8099\n",
      "Epoch 18/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4100 - accuracy: 0.8104\n",
      "Epoch 19/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4098 - accuracy: 0.8110\n",
      "Epoch 20/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4095 - accuracy: 0.8106\n",
      "Epoch 21/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4089 - accuracy: 0.8109\n",
      "Epoch 22/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4086 - accuracy: 0.8120\n",
      "Epoch 23/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4085 - accuracy: 0.8118\n",
      "Epoch 24/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4079 - accuracy: 0.8113\n",
      "Epoch 25/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4079 - accuracy: 0.8121\n",
      "Epoch 26/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4073 - accuracy: 0.8127\n",
      "Epoch 27/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4069 - accuracy: 0.8117\n",
      "Epoch 28/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4068 - accuracy: 0.8121\n",
      "Epoch 29/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4065 - accuracy: 0.8122\n",
      "Epoch 30/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4061 - accuracy: 0.8118\n",
      "Epoch 31/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4060 - accuracy: 0.8129\n",
      "Epoch 32/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4060 - accuracy: 0.8132\n",
      "Epoch 33/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4060 - accuracy: 0.8134\n",
      "Epoch 34/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4056 - accuracy: 0.8137\n",
      "Epoch 35/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4051 - accuracy: 0.8138\n",
      "Epoch 36/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4055 - accuracy: 0.8124\n",
      "Epoch 37/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4052 - accuracy: 0.8131\n",
      "Epoch 38/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4050 - accuracy: 0.8130\n",
      "Epoch 39/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4046 - accuracy: 0.8142\n",
      "Epoch 40/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4049 - accuracy: 0.8136\n",
      "Epoch 41/60\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.4046 - accuracy: 0.8136\n",
      "Epoch 42/60\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.4044 - accuracy: 0.8140\n",
      "Epoch 43/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4044 - accuracy: 0.8139\n",
      "Epoch 44/60\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.4048 - accuracy: 0.8135\n",
      "Epoch 45/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4045 - accuracy: 0.8135\n",
      "Epoch 46/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4041 - accuracy: 0.8143\n",
      "Epoch 47/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4046 - accuracy: 0.8145\n",
      "Epoch 48/60\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.4044 - accuracy: 0.8137\n",
      "Epoch 49/60\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.4046 - accuracy: 0.8146\n",
      "Epoch 50/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4043 - accuracy: 0.8138\n",
      "Epoch 51/60\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.4041 - accuracy: 0.8139\n",
      "Epoch 52/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4046 - accuracy: 0.8137\n",
      "Epoch 53/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4043 - accuracy: 0.8146\n",
      "Epoch 54/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4043 - accuracy: 0.8145\n",
      "Epoch 55/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4043 - accuracy: 0.8139\n",
      "Epoch 56/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4044 - accuracy: 0.8146\n",
      "Epoch 57/60\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.4042 - accuracy: 0.8142\n",
      "Epoch 58/60\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.4041 - accuracy: 0.8138\n",
      "Epoch 59/60\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.4039 - accuracy: 0.8141\n",
      "Epoch 60/60\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.4042 - accuracy: 0.8149\n"
     ]
    }
   ],
   "source": [
    "# Define the NN as a feed-forward model\n",
    "hard_nn = tf.keras.models.Sequential(\n",
    "    [ \n",
    "        # Create the input layer and 1st hidden layer\n",
    "        tf.keras.layers.Dense(\n",
    "            # Allot 50 neurons to the 1st hidden layer\n",
    "            units = 80,\n",
    "            # Activation Function: ReLU\n",
    "            activation = 'relu',\n",
    "            # Define the input layer to be the length of first row in training set\n",
    "            input_dim = len(X_train_scaled[0]),\n",
    "        ),\n",
    "        # Create the 2nd hidden layer\n",
    "        tf.keras.layers.Dense(\n",
    "            # ALlot 20 neurons to the 2nd layer\n",
    "            units = 20,\n",
    "            # Activation Function: Sigmoid\n",
    "            activation = 'sigmoid',\n",
    "        ),\n",
    "        # Create the output layer\n",
    "        tf.keras.layers.Dense(\n",
    "            # ALlot 1 neuron to the output layer (All-or-nothing principle)\n",
    "            units = 1,\n",
    "            # Activate Function falls on the sigmoid curve (val >= 15 : 1)\n",
    "            activation = 'sigmoid',\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "# Compile the model\n",
    "hard_nn.compile(\n",
    "    # Binary cross entropy is natural selection for a binary classifer\n",
    "    loss = \"binary_crossentropy\",\n",
    "    # RMSprop is an optimizer similar to Adam, preforming better in this case\n",
    "    # One reason for this outperformance could be RMSprop is faster to change \n",
    "    # direction on the gradient descent, making it more flexible\n",
    "    optimizer = \"RMSprop\",\n",
    "    # Evaluate model on accuracy using test data\n",
    "    metrics =  [\"accuracy\"]\n",
    ")\n",
    "# Fit the model with out preprocessed data and train it \n",
    "fit = hard_nn.fit(\n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    # Minimal loss change found after 60 epochs\n",
    "    epochs=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.4365 - accuracy: 0.7993 - 570ms/epoch - 2ms/step\n",
      "Loss: 0.4365272521972656, Accuracy: 0.7993003129959106\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the model\n",
    "model_loss, model_accuracy = hard_nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as h5 file\n",
    "hard_nn.save('models/nn_AlphabetSoup.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
